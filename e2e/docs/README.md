# End-to-End Tests

This directory contains comprehensive E2E tests for the My Claudia application using Playwright.

## Test Files

### User Workflow Tests (`user-workflows.spec.ts`)

Tests complete user workflows to ensure the application works correctly from end to end:

1. **Complete workflow test**
   - Import session from Claude CLI
   - Continue conversation in imported session
   - Upload file to conversation
   - Send message with file attachment
   - Verify all operations complete successfully

2. **Multi-project workflow test**
   - Create multiple projects
   - Import sessions to specific projects
   - Switch between projects
   - Verify project isolation (sessions don't leak between projects)
   - Verify data persistence when switching projects

3. **Data persistence workflow test**
   - Create sessions and send messages
   - Upload files
   - Refresh page and verify data persists
   - Navigate away and back, verify data intact
   - Test database persistence across multiple sessions
   - Verify data survives multiple page refreshes

### Performance Tests (`performance.spec.ts`)

Tests application performance with various loads and operations:

1. **Large session import (1000+ messages)**
   - Measures time to scan and import large session
   - Verifies rendering performance with large message history
   - Tests scroll performance with many messages
   - Threshold: < 30 seconds for import, < 3 seconds for rendering

2. **Concurrent file uploads (10 files)**
   - Tests uploading multiple files simultaneously
   - Verifies UI remains responsive during upload
   - Measures upload completion time
   - Threshold: < 5 seconds for 10 files

3. **Batch session import (100 sessions)**
   - Imports 100 sessions sequentially
   - Measures scan and import performance
   - Tests session list rendering with many items
   - Tests search/filter performance
   - Threshold: < 60 seconds for batch import

4. **Common operations performance**
   - Create new session: < 3 seconds
   - Send message: < 3 seconds
   - Open settings: < 3 seconds
   - Switch sessions: < 3 seconds
   - File attachment: < 3 seconds
   - Page refresh: < 5 seconds

5. **Database query performance**
   - Tests pagination with large datasets
   - Tests search/filter operations
   - Tests message history loading
   - Threshold: < 3 seconds for queries

6. **Memory management**
   - Creates multiple sessions
   - Rapidly switches between sessions
   - Verifies app remains responsive
   - Tests memory cleanup

## Setup

### Prerequisites

1. Install dependencies:
   ```bash
   pnpm install
   ```

2. Generate performance test fixtures:
   ```bash
   pnpm run fixtures:generate
   ```

3. Ensure both server and desktop app are running or will be started by Playwright

### Running Tests

Run all E2E tests:
```bash
pnpm run test:e2e
```

Run workflow tests only:
```bash
pnpm run test:e2e:workflows
```

Run performance tests only:
```bash
pnpm run test:e2e:performance
```

Run with UI mode (interactive):
```bash
pnpm run test:e2e:ui
```

Run in headed mode (see browser):
```bash
pnpm run test:e2e:headed
```

Debug mode:
```bash
pnpm run test:e2e:debug
```

Run specific test:
```bash
npx playwright test -g "Complete workflow"
```

## Test Structure

### Fixtures

The tests use custom fixtures defined in `e2e/helpers/setup.ts`:

- `cleanDB`: Cleans test data from database before each test
- `testProject`: Creates a test project for use in tests

### Performance Helpers

Performance utilities are available in `e2e/helpers/performance.ts`:

- `measureTime()`: Measure execution time of async operations
- `assertPerformance()`: Assert operation meets performance threshold
- `calculateStats()`: Calculate min/max/avg/median/percentiles
- `benchmark()`: Run multiple iterations and gather statistics
- `PERFORMANCE_THRESHOLDS`: Predefined thresholds for common operations

### Test Data

#### Existing Fixtures (`e2e/fixtures/`)

- `claude-cli-data/`: Sample Claude CLI data for import testing
  - `test-session-123.jsonl`: Small test session with 5 messages
  - `test-session-456.jsonl`: Test session with tool calls
  - `sessions-index.json`: Session index file

- `test-files/`: Files for upload testing
  - `sample.png`: Image file
  - `sample.pdf`: PDF document
  - `large-file.zip`: Large file for size limit testing

#### Performance Fixtures (`e2e/fixtures/performance-data/`)

Generated by `generate-fixtures.js`:

- `large-session.jsonl`: Session with 1000+ messages
- `multi-sessions/`: Directory with 100 test sessions
- `mixed-content-session.jsonl`: Session with various content types
- Test files for concurrent upload testing

## Writing New Tests

### Basic Test Structure

```typescript
import { test, expect } from '../helpers/setup';

test.describe('Feature Name', () => {
  test.beforeEach(async ({ page, cleanDB }) => {
    await page.goto('/');
    await page.waitForLoadState('networkidle');
  });

  test('should do something', async ({ page }) => {
    // Test implementation
  });
});
```

### Performance Test Structure

```typescript
import { test, expect } from '../helpers/setup';
import { measureTime, PERFORMANCE_THRESHOLDS } from '../helpers/performance';

test('performance test', async ({ page }) => {
  const { duration } = await measureTime('Operation name', async () => {
    // Operation to measure
  });

  expect(duration).toBeLessThan(PERFORMANCE_THRESHOLDS.OPERATION_NAME);
});
```

## Best Practices

1. **Always clean test data**: Use `cleanDB` fixture to ensure clean state
2. **Use proper waits**: Wait for `networkidle` or specific elements
3. **Handle async operations**: Use proper async/await patterns
4. **Check visibility**: Use `.isVisible()` with timeout and error handling
5. **Log progress**: Use console.log() to track test progress
6. **Handle failures gracefully**: Check if elements exist before interacting
7. **Measure performance**: Use performance helpers for timing-critical operations
8. **Use realistic data**: Generate fixtures that match production patterns

## Troubleshooting

### Tests are flaky
- Increase timeouts for slow operations
- Add explicit waits for elements
- Check for race conditions
- Ensure proper cleanup between tests

### Performance tests fail
- Run fixture generation: `pnpm run fixtures:generate`
- Check server and app are running
- Verify database is accessible
- Check available system resources

### Database conflicts
- Tests run sequentially (workers: 1)
- Each test cleans up test data
- Test data uses 'test-' prefix for isolation

### Import tests fail
- Verify fixture paths are correct
- Check Claude CLI data fixtures exist
- Ensure server has file system access
- Check API key configuration for actual imports

## CI/CD Integration

Tests are configured for CI in `playwright.config.ts`:

- Automatic retries: 2 attempts in CI
- Sequential execution to avoid DB conflicts
- HTML and list reporters
- Screenshots on failure
- Trace on first retry

## Performance Benchmarks

Current expected performance (on typical development machine):

| Operation | Threshold | Typical |
|-----------|-----------|---------|
| Create session | 3s | ~500ms |
| Send message | 3s | ~200ms |
| Import large session (1000 msgs) | 30s | ~15s |
| Import 100 sessions | 60s | ~30s |
| Upload 10 files | 5s | ~2s |
| Page refresh | 5s | ~2s |
| Session switch | 3s | ~300ms |
| Search/filter | 2s | ~500ms |

Note: Performance may vary based on hardware and system load.
